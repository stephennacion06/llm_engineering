{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Day 2 Exercise Solution\n",
    "# Website Summarizer using Ollama (Open Source) instead of Gemini\n",
    "\n",
    "# imports\n",
    "import requests\n",
    "import ollama\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "# Constants for Ollama\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"  # Change to \"llama3.2:1b\" if you have performance issues\n",
    "\n",
    "# Set up Ollama client using OpenAI interface (recommended approach)\n",
    "ollama_client = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# Website class adapted from Day 1 (simplified version without Confluence specifics)\n",
    "class Website:\n",
    "    \"\"\"A class to represent a website for summarization\"\"\"\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        \"\"\"Create this Website object from the given url using BeautifulSoup\"\"\"\n",
    "        self.url = url\n",
    "        \n",
    "        # Headers for web requests\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Extract title\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "            \n",
    "            # Remove unwanted elements\n",
    "            if soup.body:\n",
    "                for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\", \"nav\", \"header\", \"footer\"]):\n",
    "                    irrelevant.decompose()\n",
    "                self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = \"No content found\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.title = f\"Error: {str(e)}\"\n",
    "            self.text = \"Could not fetch website content\"\n",
    "\n",
    "# System prompt for website summarization\n",
    "system_prompt = \"\"\"You are an assistant that analyzes the contents of a website \n",
    "and provides a short summary, ignoring text that might be navigation related. \n",
    "Respond in clear, structured markdown format.\"\"\"\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    \"\"\"Create a user prompt for website summarization\"\"\"\n",
    "    user_prompt = f\"You are looking at a website titled '{website.title}'\"\n",
    "    user_prompt += \"\\n\\nThe contents of this website is as follows; \"\n",
    "    user_prompt += \"please provide a short summary of this website in markdown. \"\n",
    "    user_prompt += \"If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += \"Website content:\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "def messages_for(website):\n",
    "    \"\"\"Create messages list for LLM API call\"\"\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "# Method 1: Using ollama package directly\n",
    "def summarize_with_ollama_package(url):\n",
    "    \"\"\"Summarize website using ollama package directly\"\"\"\n",
    "    print(f\"🔍 Fetching content from: {url}\")\n",
    "    website = Website(url)\n",
    "    \n",
    "    print(f\"📄 Page title: {website.title}\")\n",
    "    print(f\"📊 Content length: {len(website.text)} characters\")\n",
    "    \n",
    "    if len(website.text) < 50:\n",
    "        return \"⚠️ **Warning**: Very little content was extracted from this website.\"\n",
    "    \n",
    "    messages = messages_for(website)\n",
    "    \n",
    "    try:\n",
    "        print(\"🤖 Generating summary with Ollama (direct package)...\")\n",
    "        response = ollama.chat(model=MODEL, messages=messages)\n",
    "        return response['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error calling Ollama: {e}\"\n",
    "\n",
    "# Method 2: Using OpenAI client with Ollama (recommended)\n",
    "def summarize_with_ollama_openai(url):\n",
    "    \"\"\"Summarize website using OpenAI client pointing to Ollama\"\"\"\n",
    "    print(f\"🔍 Fetching content from: {url}\")\n",
    "    website = Website(url)\n",
    "    \n",
    "    print(f\"📄 Page title: {website.title}\")\n",
    "    print(f\"📊 Content length: {len(website.text)} characters\")\n",
    "    \n",
    "    if len(website.text) < 50:\n",
    "        return \"⚠️ **Warning**: Very little content was extracted from this website.\"\n",
    "    \n",
    "    messages = messages_for(website)\n",
    "    \n",
    "    try:\n",
    "        print(\"🤖 Generating summary with Ollama (via OpenAI client)...\")\n",
    "        response = ollama_client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error calling Ollama: {e}\"\n",
    "\n",
    "# Method 3: Direct HTTP requests to Ollama API\n",
    "def summarize_with_requests(url):\n",
    "    \"\"\"Summarize website using direct HTTP requests to Ollama\"\"\"\n",
    "    print(f\"🔍 Fetching content from: {url}\")\n",
    "    website = Website(url)\n",
    "    \n",
    "    print(f\"📄 Page title: {website.title}\")\n",
    "    print(f\"📊 Content length: {len(website.text)} characters\")\n",
    "    \n",
    "    if len(website.text) < 50:\n",
    "        return \"⚠️ **Warning**: Very little content was extracted from this website.\"\n",
    "    \n",
    "    messages = messages_for(website)\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"🤖 Generating summary with Ollama (direct HTTP)...\")\n",
    "        response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error calling Ollama: {e}\"\n",
    "\n",
    "# Main summarization function (using the recommended OpenAI client approach)\n",
    "def summarize(url):\n",
    "    \"\"\"Main function to summarize a website using Ollama\"\"\"\n",
    "    return summarize_with_ollama_openai(url)\n",
    "\n",
    "# Display function with nice markdown formatting\n",
    "def display_summary(url):\n",
    "    \"\"\"Display website summary with nice formatting\"\"\"\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n",
    "    return summary\n",
    "\n",
    "# Enhanced function that shows comparison between methods\n",
    "def compare_ollama_methods(url):\n",
    "    \"\"\"Compare different methods of calling Ollama\"\"\"\n",
    "    print(\"🔄 Comparing different Ollama calling methods...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test all three methods\n",
    "    methods = [\n",
    "        (\"Ollama Package\", summarize_with_ollama_package),\n",
    "        (\"OpenAI Client\", summarize_with_ollama_openai),\n",
    "        (\"Direct HTTP\", summarize_with_requests)\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for method_name, method_func in methods:\n",
    "        print(f\"\\n🧪 Testing {method_name}:\")\n",
    "        print(\"-\" * 30)\n",
    "        try:\n",
    "            result = method_func(url)\n",
    "            results[method_name] = result\n",
    "            print(\"✅ Success!\")\n",
    "        except Exception as e:\n",
    "            results[method_name] = f\"❌ Failed: {e}\"\n",
    "            print(f\"❌ Failed: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test the implementation\n",
    "print(\"🚀 Testing Ollama Website Summarizer\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test with a simple website first\n",
    "test_url = \"https://www.python.org\"\n",
    "\n",
    "print(f\"\\n📝 Summarizing: {test_url}\")\n",
    "display_summary(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with more websites\n",
    "test_websites = [\n",
    "    \"https://www.bbc.com\",\n",
    "    \"https://techcrunch.com\", \n",
    "    \"https://github.com\",\n",
    "    \"https://stackoverflow.com\"\n",
    "]\n",
    "\n",
    "print(\"🌐 Testing multiple websites...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for url in test_websites:\n",
    "    print(f\"\\n📄 Summarizing: {url}\")\n",
    "    try:\n",
    "        summary = summarize(url)\n",
    "        print(f\"✅ Success! Summary length: {len(summary)} characters\")\n",
    "        display(Markdown(f\"### {url}\\n{summary}\"))\n",
    "        print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to summarize {url}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "CONFLUENCE ANALYZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Day 2 Exercise Solution - Confluence Analyzer using Ollama (NO OpenAI dependency)\n",
    "# Based on day1.ipynb ConfluenceContent class but adapted for Ollama only\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import ollama\n",
    "import urllib3\n",
    "from urllib.parse import urlparse, unquote\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Constants for Ollama\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"  # Change to \"llama3.2:1b\" if you have performance issues\n",
    "\n",
    "# Disable SSL warnings for corporate networks\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Headers for web requests\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class ConfluenceContent:\n",
    "    \"\"\"A class to extract and prepare Confluence content for LLM summarization using Ollama\"\"\"\n",
    "    \n",
    "    def __init__(self, url, use_api=True):\n",
    "        self.url = url\n",
    "        self.title = \"\"\n",
    "        self.text = \"\"\n",
    "        self.page_id = None\n",
    "        self.space_key = None\n",
    "        \n",
    "        # Try to extract page info from URL\n",
    "        self._parse_url()\n",
    "        \n",
    "        # Load credentials from environment\n",
    "        self.token = os.getenv('CONFLUENCE_TOKEN')\n",
    "        self.base_url = os.getenv('CONFLUENCE_URL')\n",
    "        \n",
    "        if use_api and self.token and self.base_url:\n",
    "            success = self._fetch_via_api()\n",
    "            if not success:\n",
    "                print(\"API failed, falling back to web scraping...\")\n",
    "                self._fetch_via_web()\n",
    "        else:\n",
    "            self._fetch_via_web()\n",
    "    \n",
    "    def _parse_url(self):\n",
    "        \"\"\"Extract space key and page title from Confluence URL\"\"\"\n",
    "        # URL formats:\n",
    "        # /display/SPACEKEY/Page+Title\n",
    "        # /pages/viewpage.action?pageId=123456\n",
    "        \n",
    "        match = re.search(r'/display/([^/]+)/(.+)', self.url)\n",
    "        if match:\n",
    "            self.space_key = match.group(1)\n",
    "            page_title = unquote(match.group(2)).replace('+', ' ')\n",
    "            self.page_title = page_title\n",
    "            return\n",
    "        \n",
    "        match = re.search(r'pageId=(\\d+)', self.url)\n",
    "        if match:\n",
    "            self.page_id = match.group(1)\n",
    "            return\n",
    "    \n",
    "    def _fetch_via_api(self):\n",
    "        \"\"\"Fetch content using Confluence REST API\"\"\"\n",
    "        try:\n",
    "            session = requests.Session()\n",
    "            session.headers.update({\n",
    "                'Authorization': f'Bearer {self.token}',\n",
    "                'Content-Type': 'application/json',\n",
    "                'Accept': 'application/json'\n",
    "            })\n",
    "            \n",
    "            if self.page_id:\n",
    "                # Direct page ID lookup\n",
    "                url = f\"{self.base_url}/rest/api/content/{self.page_id}\"\n",
    "                params = {'expand': 'body.storage,space,version,title'}\n",
    "                response = session.get(url, params=params, verify=False)\n",
    "            \n",
    "            elif self.space_key and hasattr(self, 'page_title'):\n",
    "                # Search by title in space\n",
    "                url = f\"{self.base_url}/rest/api/content/search\"\n",
    "                cql_query = f\"space='{self.space_key}' AND title~'{self.page_title}'\"\n",
    "                params = {\n",
    "                    'cql': cql_query,\n",
    "                    'expand': 'body.storage,space,version,title',\n",
    "                    'limit': 1\n",
    "                }\n",
    "                response = session.get(url, params=params, verify=False)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    if data.get('results'):\n",
    "                        content = data['results'][0]\n",
    "                    else:\n",
    "                        return False\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                if 'results' not in locals():\n",
    "                    content = response.json()\n",
    "                \n",
    "                self.title = content.get('title', 'No title')\n",
    "                \n",
    "                # Extract text from storage format\n",
    "                if content.get('body', {}).get('storage', {}).get('value'):\n",
    "                    storage_content = content['body']['storage']['value']\n",
    "                    # Parse HTML and extract clean text\n",
    "                    soup = BeautifulSoup(storage_content, 'html.parser')\n",
    "                    # Remove unwanted elements\n",
    "                    for tag in soup(['script', 'style', 'meta', 'link']):\n",
    "                        tag.decompose()\n",
    "                    self.text = soup.get_text(separator='\\n', strip=True)\n",
    "                else:\n",
    "                    return False\n",
    "                \n",
    "                return True\n",
    "            else:\n",
    "                print(f\"API Error {response.status_code}: {response.text[:200]}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"API fetch failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _fetch_via_web(self):\n",
    "        \"\"\"Fallback to web scraping\"\"\"\n",
    "        try:\n",
    "            session = requests.Session()\n",
    "            \n",
    "            # Add token to headers if available\n",
    "            if self.token:\n",
    "                session.headers.update({\n",
    "                    'Authorization': f'Bearer {self.token}',\n",
    "                    'X-Atlassian-Token': 'no-check'\n",
    "                })\n",
    "            \n",
    "            session.headers.update(headers)\n",
    "            \n",
    "            response = session.get(self.url, verify=False, timeout=30)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                self.title = f\"HTTP Error {response.status_code}\"\n",
    "                self.text = \"Could not fetch page content\"\n",
    "                return\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Extract title\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "            \n",
    "            # Look for Confluence-specific content areas\n",
    "            content_areas = [\n",
    "                {'id': 'main-content'},\n",
    "                {'class': 'wiki-content'},\n",
    "                {'class': 'page-content'},\n",
    "                {'id': 'content'},\n",
    "                {'class': 'main-content'}\n",
    "            ]\n",
    "            \n",
    "            main_content = None\n",
    "            for selector in content_areas:\n",
    "                main_content = soup.find('div', selector)\n",
    "                if main_content:\n",
    "                    break\n",
    "            \n",
    "            # If no specific content area found, use body\n",
    "            if not main_content:\n",
    "                main_content = soup.body\n",
    "            \n",
    "            if main_content:\n",
    "                # Remove navigation, sidebar, and other irrelevant elements\n",
    "                for irrelevant in main_content(['script', 'style', 'img', 'input', \n",
    "                                              'nav', 'header', 'footer', 'sidebar',\n",
    "                                              'breadcrumbs', 'comment']):\n",
    "                    irrelevant.decompose()\n",
    "                \n",
    "                # Remove elements with navigation-related classes\n",
    "                nav_classes = ['nav', 'navigation', 'menu', 'sidebar', 'breadcrumb', \n",
    "                              'header', 'footer', 'comment', 'metadata']\n",
    "                for nav_class in nav_classes:\n",
    "                    for element in main_content.find_all(class_=re.compile(nav_class, re.I)):\n",
    "                        element.decompose()\n",
    "                \n",
    "                self.text = main_content.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = \"No content found\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Web scraping failed: {e}\")\n",
    "            self.title = \"Fetch Failed\"\n",
    "            self.text = f\"Error fetching content: {e}\"\n",
    "\n",
    "# System prompt for Confluence analysis with Ollama\n",
    "confluence_system_prompt = \"\"\"You are an AI assistant specialized in analyzing and summarizing technical documentation and internal knowledge base content from Confluence pages.\n",
    "\n",
    "Your task is to:\n",
    "1. Identify the main purpose and scope of the document\n",
    "2. Extract key technical information, procedures, or findings\n",
    "3. Highlight important conclusions or recommendations\n",
    "4. Present the summary in clear, structured markdown\n",
    "5. Ignore navigation elements, metadata, or administrative content\n",
    "\n",
    "Focus on the substantive content that would be valuable for someone trying to understand the topic. Respond in markdown format.\"\"\"\n",
    "\n",
    "def user_prompt_for_confluence(confluence_content):\n",
    "    \"\"\"Create a user prompt optimized for Confluence content summarization\"\"\"\n",
    "    user_prompt = f\"You are analyzing a Confluence page titled: '{confluence_content.title}'\\n\\n\"\n",
    "    user_prompt += \"This appears to be internal documentation or knowledge base content. \"\n",
    "    user_prompt += \"Please provide a comprehensive summary that captures:\\n\"\n",
    "    user_prompt += \"- Main purpose/objective of the document\\n\"\n",
    "    user_prompt += \"- Key technical details or findings\\n\"\n",
    "    user_prompt += \"- Important procedures or steps mentioned\\n\"\n",
    "    user_prompt += \"- Any conclusions or recommendations\\n\\n\"\n",
    "    user_prompt += \"Content to analyze:\\n\\n\"\n",
    "    user_prompt += confluence_content.text\n",
    "    return user_prompt\n",
    "\n",
    "def messages_for_confluence(confluence_content):\n",
    "    \"\"\"Create messages list for Confluence analysis using Ollama\"\"\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": confluence_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for_confluence(confluence_content)}\n",
    "    ]\n",
    "\n",
    "# Method 1: Using ollama package directly for Confluence (RECOMMENDED - NO OPENAI)\n",
    "def summarize_confluence_with_ollama_package(url):\n",
    "    \"\"\"Summarize Confluence page using ollama package directly\"\"\"\n",
    "    print(f\"🔍 Fetching Confluence content from: {url}\")\n",
    "    confluence_content = ConfluenceContent(url)\n",
    "    \n",
    "    print(f\"📄 Page title: {confluence_content.title}\")\n",
    "    print(f\"📊 Content length: {len(confluence_content.text)} characters\")\n",
    "    \n",
    "    if len(confluence_content.text) < 100:\n",
    "        return \"⚠️ **Warning**: Very little content was extracted. This might indicate authentication issues or the page structure wasn't recognized properly.\"\n",
    "    \n",
    "    messages = messages_for_confluence(confluence_content)\n",
    "    \n",
    "    try:\n",
    "        print(\"🤖 Generating Confluence summary with Ollama (direct package)...\")\n",
    "        response = ollama.chat(model=MODEL, messages=messages)\n",
    "        return response['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error calling Ollama: {e}\"\n",
    "\n",
    "# Method 2: Direct HTTP requests to Ollama API for Confluence (ALTERNATIVE - NO OPENAI)\n",
    "def summarize_confluence_with_requests(url):\n",
    "    \"\"\"Summarize Confluence page using direct HTTP requests to Ollama\"\"\"\n",
    "    print(f\"🔍 Fetching Confluence content from: {url}\")\n",
    "    confluence_content = ConfluenceContent(url)\n",
    "    \n",
    "    print(f\"📄 Page title: {confluence_content.title}\")\n",
    "    print(f\"📊 Content length: {len(confluence_content.text)} characters\")\n",
    "    \n",
    "    if len(confluence_content.text) < 100:\n",
    "        return \"⚠️ **Warning**: Very little content was extracted. This might indicate authentication issues or the page structure wasn't recognized properly.\"\n",
    "    \n",
    "    messages = messages_for_confluence(confluence_content)\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"🤖 Generating Confluence summary with Ollama (direct HTTP)...\")\n",
    "        response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error calling Ollama: {e}\"\n",
    "\n",
    "# Main Confluence summarization function (using ollama package - NO OPENAI)\n",
    "def summarize_confluence_page(url):\n",
    "    \"\"\"Main function to summarize a Confluence page using Ollama (no OpenAI dependency)\"\"\"\n",
    "    return summarize_confluence_with_ollama_package(url)\n",
    "\n",
    "# Display function with nice markdown formatting for Confluence\n",
    "def display_confluence_summary(url):\n",
    "    \"\"\"Display Confluence page summary with nice formatting\"\"\"\n",
    "    summary = summarize_confluence_page(url)\n",
    "    display(Markdown(summary))\n",
    "    return summary\n",
    "\n",
    "# Enhanced function that shows comparison between pure Ollama methods (NO OPENAI)\n",
    "def compare_pure_ollama_methods(url):\n",
    "    \"\"\"Compare different methods of calling Ollama without OpenAI dependency\"\"\"\n",
    "    print(\"🔄 Comparing pure Ollama methods (NO OpenAI dependency)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test both pure methods\n",
    "    methods = [\n",
    "        (\"Ollama Package\", summarize_confluence_with_ollama_package),\n",
    "        (\"Direct HTTP\", summarize_confluence_with_requests)\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for method_name, method_func in methods:\n",
    "        print(f\"\\n🧪 Testing {method_name}:\")\n",
    "        print(\"-\" * 30)\n",
    "        try:\n",
    "            result = method_func(url)\n",
    "            results[method_name] = result\n",
    "            print(\"✅ Success!\")\n",
    "        except Exception as e:\n",
    "            results[method_name] = f\"❌ Failed: {e}\"\n",
    "            print(f\"❌ Failed: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Simple Website class (no OpenAI dependency)\n",
    "class Website:\n",
    "    \"\"\"A class to represent a website for summarization\"\"\"\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        \"\"\"Create this Website object from the given url using BeautifulSoup\"\"\"\n",
    "        self.url = url\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Extract title\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "            \n",
    "            # Remove unwanted elements\n",
    "            if soup.body:\n",
    "                for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\", \"nav\", \"header\", \"footer\"]):\n",
    "                    irrelevant.decompose()\n",
    "                self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = \"No content found\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.title = f\"Error: {str(e)}\"\n",
    "            self.text = \"Could not fetch website content\"\n",
    "\n",
    "# Website summarization functions (no OpenAI dependency)\n",
    "def summarize_website_with_ollama(url):\n",
    "    \"\"\"Summarize website using ollama package directly\"\"\"\n",
    "    print(f\"🔍 Fetching content from: {url}\")\n",
    "    website = Website(url)\n",
    "    \n",
    "    print(f\"📄 Page title: {website.title}\")\n",
    "    print(f\"📊 Content length: {len(website.text)} characters\")\n",
    "    \n",
    "    if len(website.text) < 50:\n",
    "        return \"⚠️ **Warning**: Very little content was extracted from this website.\"\n",
    "    \n",
    "    # Create messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that analyzes website content and provides concise summaries in markdown format.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize this website titled '{website.title}':\\n\\n{website.text}\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        print(\"🤖 Generating summary with Ollama...\")\n",
    "        response = ollama.chat(model=MODEL, messages=messages)\n",
    "        return response['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error calling Ollama: {e}\"\n",
    "\n",
    "def summarize_website_with_requests(url):\n",
    "    \"\"\"Summarize website using direct HTTP requests to Ollama\"\"\"\n",
    "    print(f\"🔍 Fetching content from: {url}\")\n",
    "    website = Website(url)\n",
    "    \n",
    "    print(f\"📄 Page title: {website.title}\")\n",
    "    print(f\"📊 Content length: {len(website.text)} characters\")\n",
    "    \n",
    "    if len(website.text) < 50:\n",
    "        return \"⚠️ **Warning**: Very little content was extracted from this website.\"\n",
    "    \n",
    "    # Create messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that analyzes website content and provides concise summaries in markdown format.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize this website titled '{website.title}':\\n\\n{website.text}\"}\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"🤖 Generating summary with Ollama (HTTP)...\")\n",
    "        response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error calling Ollama: {e}\"\n",
    "\n",
    "# Main website summarization function\n",
    "def summarize_website(url):\n",
    "    \"\"\"Main function to summarize a website using Ollama (no OpenAI)\"\"\"\n",
    "    return summarize_website_with_ollama(url)\n",
    "\n",
    "def display_website_summary(url):\n",
    "    \"\"\"Display website summary with nice formatting\"\"\"\n",
    "    summary = summarize_website(url)\n",
    "    display(Markdown(summary))\n",
    "    return summary\n",
    "\n",
    "# Test the implementation\n",
    "print(\"🚀 Testing Pure Ollama Analyzer (NO OpenAI dependency)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test with website\n",
    "# print(\"\\n🌐 Testing website summarization...\")\n",
    "# test_url = \"https://www.python.org\"\n",
    "# print(f\"📝 Summarizing: {test_url}\")\n",
    "# display_website_summary(test_url)\n",
    "\n",
    "# Test with Confluence\n",
    "print(\"\\n🏢 Testing Confluence analysis...\")\n",
    "# Insert your Confluence test URL here\n",
    "# confluence_test_url = \"\"\n",
    "\n",
    "# Uncomment to test with your Confluence URL:\n",
    "# print(f\"\\n📝 Analyzing Confluence page: {confluence_test_url}\")\n",
    "# display_confluence_summary(confluence_test_url)\n",
    "\n",
    "print(\"\\n💡 Available functions (NO OpenAI dependency):\")\n",
    "print(\"- display_website_summary('url') - Summarize any website\")\n",
    "print(\"- display_confluence_summary('url') - Analyze Confluence pages\")  \n",
    "print(\"- compare_pure_ollama_methods('url') - Compare Ollama connection methods\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
