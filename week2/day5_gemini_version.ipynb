{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Project - Airline AI Assistant with Gemini (Multi-Modal)\n",
    "\n",
    "We'll bring together everything we've learned to make a multi-modal AI Customer Support assistant for an Airline using Google's Gemini.\n",
    "\n",
    "This version includes:\n",
    "- **Conversational chat** with history\n",
    "- **Function calling** (tools) to get ticket prices\n",
    "- **Image generation** using Imagen (Google's image model)\n",
    "- **Text-to-Speech** (optional, using Google's TTS or alternative)\n",
    "\n",
    "## What Makes This \"Agentic AI\"?\n",
    "\n",
    "1. **Multiple specialized capabilities** (chat, tools, image generation)\n",
    "2. **Tool use** to access external information\n",
    "3. **Multi-modal outputs** (text, images, audio)\n",
    "4. **Memory** through conversation history\n",
    "5. **Autonomous decision-making** about when to use tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Run this cell once to install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation cell - run once, then restart kernel\n",
    "!pip install -q -U google-genai gradio python-dotenv pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from PIL import Image\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "if google_api_key:\n",
    "    print(f\"✓ Google API Key exists and begins {google_api_key[:8]}\")\n",
    "    client = genai.Client(api_key=google_api_key)\n",
    "else:\n",
    "    print(\"✗ Google API Key not set\")\n",
    "    \n",
    "MODEL = \"gemini-2.0-flash-exp\"  # Latest Gemini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Simple Chat (No Tools Yet)\n",
    "\n",
    "Let's start with basic conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_simple(message, history):\n",
    "    \"\"\"Simple chat without tools\"\"\"\n",
    "    gemini_history = []\n",
    "    for msg in history:\n",
    "        role = \"model\" if msg[\"role\"] == \"assistant\" else \"user\"\n",
    "        gemini_history.append({\n",
    "            \"role\": role,\n",
    "            \"parts\": [{\"text\": msg[\"content\"]}]\n",
    "        })\n",
    "    \n",
    "    gemini_history.append({\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [{\"text\": message}]\n",
    "    })\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=gemini_history,\n",
    "        config={\"system_instruction\": system_message}\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "gr.ChatInterface(fn=chat_simple, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Adding Tools - Flight Pricing\n",
    "\n",
    "Now let's give our assistant the ability to look up ticket prices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a useful function\n",
    "\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the price of a return ticket to the destination city.\n",
    "    Call this whenever you need to know the ticket price.\n",
    "    \n",
    "    Args:\n",
    "        destination_city: The city that the customer wants to travel to\n",
    "    \n",
    "    Returns:\n",
    "        The price of the ticket as a string\n",
    "    \"\"\"\n",
    "    print(f\"🔧 Tool called: get_ticket_price('{destination_city}')\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it\n",
    "get_ticket_price(\"London\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Gemini Function Calling\n",
    "\n",
    "Gemini's function calling is elegant - just pass the Python function and Gemini figures out when to call it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_tools(message, history):\n",
    "    \"\"\"Chat with tool/function calling capability\"\"\"\n",
    "    # Convert history\n",
    "    gemini_history = []\n",
    "    for msg in history:\n",
    "        role = \"model\" if msg[\"role\"] == \"assistant\" else \"user\"\n",
    "        gemini_history.append({\n",
    "            \"role\": role,\n",
    "            \"parts\": [{\"text\": msg[\"content\"]}]\n",
    "        })\n",
    "    \n",
    "    gemini_history.append({\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [{\"text\": message}]\n",
    "    })\n",
    "    \n",
    "    # First request with tool declaration\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=gemini_history,\n",
    "        config={\n",
    "            \"system_instruction\": system_message,\n",
    "            \"tools\": [get_ticket_price]  # Pass the function directly!\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Check if Gemini wants to call a function\n",
    "    if response.candidates[0].content.parts[0].function_call:\n",
    "        function_call = response.candidates[0].content.parts[0].function_call\n",
    "        \n",
    "        # Extract function name and arguments\n",
    "        function_name = function_call.name\n",
    "        function_args = dict(function_call.args)\n",
    "        \n",
    "        print(f\"\\n🤖 Gemini wants to call: {function_name}({function_args})\")\n",
    "        \n",
    "        # Execute the function\n",
    "        if function_name == \"get_ticket_price\":\n",
    "            result = get_ticket_price(**function_args)\n",
    "            \n",
    "            # Add function call and result to history\n",
    "            gemini_history.append({\n",
    "                \"role\": \"model\",\n",
    "                \"parts\": [{\"function_call\": function_call}]\n",
    "            })\n",
    "            gemini_history.append({\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\n",
    "                    \"function_response\": {\n",
    "                        \"name\": function_name,\n",
    "                        \"response\": {\"price\": result}\n",
    "                    }\n",
    "                }]\n",
    "            })\n",
    "            \n",
    "            # Get final response\n",
    "            final_response = client.models.generate_content(\n",
    "                model=MODEL,\n",
    "                contents=gemini_history,\n",
    "                config={\n",
    "                    \"system_instruction\": system_message,\n",
    "                    \"tools\": [get_ticket_price]\n",
    "                }\n",
    "            )\n",
    "            return final_response.text\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "gr.ChatInterface(fn=chat_with_tools, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Multi-Modal: Destination Preview Images\n",
    "\n",
    "**Important Note**: Unlike OpenAI's DALL-E, Google Gemini doesn't have a direct image generation API in the `google-genai` SDK. Imagen (Google's image model) requires Vertex AI setup.\n",
    "\n",
    "Instead, we'll create **AI-powered destination preview cards** that:\n",
    "1. Use Gemini to generate vivid destination descriptions\n",
    "2. Create beautiful visual cards with those descriptions\n",
    "3. Demonstrate multi-modal thinking without additional APIs\n",
    "\n",
    "This approach works immediately and can be easily swapped for real image generation later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city: str) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Generate a destination preview card with AI-generated description.\n",
    "    Uses Gemini to create vivid descriptions, then creates an attractive visual card.\n",
    "    \n",
    "    Args:\n",
    "        city: The destination city\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image object with AI-generated description\n",
    "    \"\"\"\n",
    "    print(f\"🎨 Creating destination preview for {city}...\")\n",
    "    \n",
    "    # Use Gemini to generate a vivid description\n",
    "    try:\n",
    "        description_prompt = f\"In 1-2 vivid sentences, describe the most iconic and beautiful aspects of {city} that would make someone want to visit. Be specific, evocative, and exciting. Mention landmarks, culture, or atmosphere.\"\n",
    "        \n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL,\n",
    "            contents=[{\"role\": \"user\", \"parts\": [{\"text\": description_prompt}]}]\n",
    "        )\n",
    "        \n",
    "        description = response.text.strip()\n",
    "        print(f\"✨ AI Description: {description[:100]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Description generation error: {e}\")\n",
    "        description = f\"Experience the beauty and culture of {city}!\"\n",
    "    \n",
    "    # Create an attractive preview card\n",
    "    from PIL import ImageDraw, ImageFont\n",
    "    import textwrap\n",
    "    \n",
    "    # Color schemes for different cities\n",
    "    color_schemes = {\n",
    "        \"paris\": (\"#E8D5F2\", \"#6B2D5C\"),      # Lavender & Purple\n",
    "        \"london\": (\"#D4E5F7\", \"#1A3A52\"),     # Light Blue & Navy\n",
    "        \"tokyo\": (\"#FFE5EC\", \"#C41E3A\"),      # Pink & Red\n",
    "        \"berlin\": (\"#D5F5E3\", \"#196F3D\"),     # Light Green & Dark Green\n",
    "        \"new york\": (\"#FFF8DC\", \"#DAA520\"),   # Cornsilk & Goldenrod\n",
    "        \"rome\": (\"#FAEBD7\", \"#8B4513\"),       # Antique White & Saddle Brown\n",
    "        \"barcelona\": (\"#FFE4B5\", \"#FF6347\"),  # Moccasin & Tomato\n",
    "        \"sydney\": (\"#F0F8FF\", \"#4682B4\"),     # Alice Blue & Steel Blue\n",
    "    }\n",
    "    \n",
    "    bg_color, text_color = color_schemes.get(\n",
    "        city.lower(), \n",
    "        (\"#E0F7FA\", \"#006064\")  # Cyan & Dark Cyan (default)\n",
    "    )\n",
    "    \n",
    "    # Create high-quality image\n",
    "    img = Image.new('RGB', (1024, 1024), color=bg_color)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Try to use nice fonts, fall back to default if not available\n",
    "    try:\n",
    "        title_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 80)\n",
    "        desc_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 36)\n",
    "        small_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 28)\n",
    "    except:\n",
    "        title_font = ImageFont.load_default()\n",
    "        desc_font = ImageFont.load_default()\n",
    "        small_font = ImageFont.load_default()\n",
    "    \n",
    "    # Draw decorative header\n",
    "    draw.rectangle([0, 0, 1024, 150], fill=text_color)\n",
    "    \n",
    "    # Draw city name\n",
    "    title = city.upper()\n",
    "    title_bbox = draw.textbbox((0, 0), title, font=title_font)\n",
    "    title_width = title_bbox[2] - title_bbox[0]\n",
    "    title_x = (1024 - title_width) // 2\n",
    "    draw.text((title_x, 35), title, fill=bg_color, font=title_font)\n",
    "    \n",
    "    # Draw AI-generated description (wrapped)\n",
    "    wrapped_lines = textwrap.wrap(description, width=45)\n",
    "    y_offset = 220\n",
    "    \n",
    "    for line in wrapped_lines:\n",
    "        bbox = draw.textbbox((0, 0), line, font=desc_font)\n",
    "        line_width = bbox[2] - bbox[0]\n",
    "        x = (1024 - line_width) // 2\n",
    "        draw.text((x, y_offset), line, fill=text_color, font=desc_font)\n",
    "        y_offset += 55\n",
    "    \n",
    "    # Add decorative elements\n",
    "    # Circle with airplane icon\n",
    "    draw.ellipse([362, 700, 662, 1000], fill=text_color)\n",
    "    draw.text((460, 805), \"✈️\", font=title_font, fill=bg_color)\n",
    "    \n",
    "    # Add \"AI-Generated Preview\" label at bottom\n",
    "    label = \"AI-Powered Destination Preview\"\n",
    "    label_bbox = draw.textbbox((0, 0), label, font=small_font)\n",
    "    label_width = label_bbox[2] - label_bbox[0]\n",
    "    label_x = (1024 - label_width) // 2\n",
    "    draw.text((label_x, 950), label, fill=text_color, font=small_font)\n",
    "    \n",
    "    print(f\"✓ Created preview card for {city}\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the AI-powered destination preview\n",
    "test_image = artist(\"Paris\")\n",
    "display(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Alternative: Integration with Real Image Generation\n",
    "\n",
    "If you want actual AI-generated images (not preview cards), you have several options:\n",
    "\n",
    "### Option 1: Google Vertex AI + Imagen\n",
    "Requires Google Cloud setup but gives you access to Imagen:\n",
    "```python\n",
    "# Requires: pip install google-cloud-aiplatform\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=\"your-project-id\", location=\"us-central1\")\n",
    "\n",
    "def generate_with_imagen(prompt):\n",
    "    model = aiplatform.Model(\"imagegeneration@002\")\n",
    "    response = model.predict(instances=[{\"prompt\": prompt}])\n",
    "    # Process response...\n",
    "```\n",
    "\n",
    "### Option 2: Mix OpenAI DALL-E with Gemini Chat\n",
    "Use Gemini for chat and OpenAI for images:\n",
    "```python\n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def artist_dalle(city):\n",
    "    response = openai_client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=f\"Beautiful vacation destination image of {city}\",\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "    # Download and return image...\n",
    "```\n",
    "\n",
    "### Option 3: Other Image APIs\n",
    "- Stability AI (Stable Diffusion)\n",
    "- Midjourney API\n",
    "- Replicate\n",
    "- Many others!\n",
    "\n",
    "For this tutorial, our AI-powered preview cards demonstrate the multi-modal concept perfectly! 🎨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_simple_fallback(city: str) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Super simple fallback - creates a basic colored image with city name.\n",
    "    Use this only if the main artist() function fails completely.\n",
    "    \"\"\"\n",
    "    from PIL import ImageDraw\n",
    "    \n",
    "    img = Image.new('RGB', (512, 512), color='skyblue')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    text = f\"Visit {city}!\"\n",
    "    bbox = draw.textbbox((0, 0), text)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "    \n",
    "    position = ((512 - text_width) // 2, (512 - text_height) // 2)\n",
    "    draw.text(position, text, fill='white')\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Audio/Text-to-Speech (Optional)\n",
    "\n",
    "Google Cloud has Text-to-Speech, but it requires separate setup. For simplicity, we'll skip audio in this Gemini version.\n",
    "\n",
    "If you want audio, you can:\n",
    "1. Use Google Cloud Text-to-Speech API (requires separate authentication)\n",
    "2. Use a different TTS service\n",
    "3. Use the browser's built-in speech synthesis (via Gradio)\n",
    "\n",
    "For now, we'll focus on chat + tools + images!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## The Complete Agentic Assistant\n",
    "\n",
    "Now let's put it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_complete(history):\n",
    "    \"\"\"\n",
    "    Complete chat function with tools and AI-generated destination previews.\n",
    "    This is our \"agentic\" assistant!\n",
    "    \"\"\"\n",
    "    # Convert history (last message is from user)\n",
    "    gemini_history = []\n",
    "    for msg in history:\n",
    "        role = \"model\" if msg[\"role\"] == \"assistant\" else \"user\"\n",
    "        gemini_history.append({\n",
    "            \"role\": role,\n",
    "            \"parts\": [{\"text\": msg[\"content\"]}]\n",
    "        })\n",
    "    \n",
    "    image = None\n",
    "    \n",
    "    # First request with tools\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=gemini_history,\n",
    "        config={\n",
    "            \"system_instruction\": system_message,\n",
    "            \"tools\": [get_ticket_price]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Handle function calls\n",
    "    if response.candidates[0].content.parts[0].function_call:\n",
    "        function_call = response.candidates[0].content.parts[0].function_call\n",
    "        function_name = function_call.name\n",
    "        function_args = dict(function_call.args)\n",
    "        \n",
    "        # Execute function\n",
    "        if function_name == \"get_ticket_price\":\n",
    "            result = get_ticket_price(**function_args)\n",
    "            city = function_args.get('destination_city', '')\n",
    "            \n",
    "            # Generate AI-powered destination preview\n",
    "            print(f\"🎨 Creating destination preview for {city}...\")\n",
    "            try:\n",
    "                image = artist(city)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Main artist failed: {e}\")\n",
    "                print(\"Using simple fallback...\")\n",
    "                image = artist_simple_fallback(city)\n",
    "            \n",
    "            # Add to history\n",
    "            gemini_history.append({\n",
    "                \"role\": \"model\",\n",
    "                \"parts\": [{\"function_call\": function_call}]\n",
    "            })\n",
    "            gemini_history.append({\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\n",
    "                    \"function_response\": {\n",
    "                        \"name\": function_name,\n",
    "                        \"response\": {\"price\": result}\n",
    "                    }\n",
    "                }]\n",
    "            })\n",
    "            \n",
    "            # Get final response\n",
    "            final_response = client.models.generate_content(\n",
    "                model=MODEL,\n",
    "                contents=gemini_history,\n",
    "                config={\n",
    "                    \"system_instruction\": system_message,\n",
    "                    \"tools\": [get_ticket_price]\n",
    "                }\n",
    "            )\n",
    "            reply = final_response.text\n",
    "    else:\n",
    "        reply = response.text\n",
    "    \n",
    "    # Add assistant's reply to history\n",
    "    history += [{\"role\": \"assistant\", \"content\": reply}]\n",
    "    \n",
    "    return history, image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Launch the Complete Assistant!\n",
    "\n",
    "This creates a full UI with:\n",
    "- Chat interface with conversation history\n",
    "- AI-generated destination preview cards\n",
    "- Automatic tool calling for flight prices\n",
    "- Multi-modal outputs (text + images)\n",
    "\n",
    "**How it works:**\n",
    "1. You ask about a flight price\n",
    "2. Gemini calls the `get_ticket_price` tool\n",
    "3. System generates an AI-powered preview card with Gemini's description\n",
    "4. Everything displays in a beautiful interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Gradio interface\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    gr.Markdown(\"# ✈️ FlightAI Assistant (Powered by Gemini)\")\n",
    "    gr.Markdown(\"Ask about flight prices and see destination images!\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500, label=\"Destination Preview\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(\n",
    "            label=\"Your message:\",\n",
    "            placeholder=\"Try: 'How much is a ticket to Paris?'\"\n",
    "        )\n",
    "    \n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Send\", variant=\"primary\")\n",
    "        clear_btn = gr.Button(\"Clear\")\n",
    "    \n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\": \"user\", \"content\": message}]\n",
    "        return \"\", history\n",
    "    \n",
    "    # Wire up the interface\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat_complete, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "    \n",
    "    submit_btn.click(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat_complete, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(lambda: (None, None), inputs=None, outputs=[chatbot, image_output], queue=False)\n",
    "\n",
    "ui.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Try These Queries:\n",
    "\n",
    "1. \"How much is a ticket to London?\"\n",
    "2. \"What's the price for Tokyo?\"\n",
    "3. \"I want to fly to Paris\"\n",
    "4. \"Tell me about Berlin flights\"\n",
    "\n",
    "Notice how the assistant:\n",
    "- ✅ Calls the pricing function automatically\n",
    "- ✅ Uses Gemini to generate vivid destination descriptions\n",
    "- ✅ Creates beautiful preview cards with AI-generated content\n",
    "- ✅ Maintains conversation context\n",
    "- ✅ Responds naturally\n",
    "\n",
    "**What makes this \"multi-modal\"?**\n",
    "- Text input and output (chat)\n",
    "- Visual output (destination preview cards)\n",
    "- Tool integration (function calling)\n",
    "- AI-generated descriptions (creative content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Exercises and Business Applications\n",
    "\n",
    "### Extend This Project:\n",
    "\n",
    "1. **Add more tools**:\n",
    "   - `book_flight(city, date)` - Simulates booking\n",
    "   - `check_availability(city, date)` - Check seat availability\n",
    "   - `cancel_booking(booking_id)` - Cancel reservations\n",
    "\n",
    "2. **Enhance image generation**:\n",
    "   - Use Gemini's vision to describe destinations\n",
    "   - Generate travel itineraries with images\n",
    "   - Create personalized vacation mood boards\n",
    "\n",
    "3. **Add real data**:\n",
    "   - Connect to real flight APIs\n",
    "   - Use actual pricing data\n",
    "   - Integrate with booking systems\n",
    "\n",
    "4. **Business applications**:\n",
    "   - Customer support chatbot for your business\n",
    "   - Product recommendation engine with images\n",
    "   - Virtual shopping assistant\n",
    "   - Real estate showing assistant\n",
    "   - Restaurant recommendation system\n",
    "\n",
    "### Key Learnings:\n",
    "\n",
    "- ✅ Multi-modal AI combines text, images, and more\n",
    "- ✅ Function calling enables AI to use external tools\n",
    "- ✅ Gemini makes tool integration simple\n",
    "- ✅ Agentic AI can orchestrate multiple capabilities\n",
    "- ✅ Gradio makes professional UIs easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Comparison: Gemini vs OpenAI for Multi-Modal\n",
    "\n",
    "| Feature | Gemini | OpenAI |\n",
    "|---------|--------|--------|\n",
    "| **Text Generation** | Gemini 2.0 Flash | GPT-4o-mini |\n",
    "| **Image Generation** | Imagen 3.0 | DALL-E 3 |\n",
    "| **Function Calling** | Pass Python functions directly | JSON schema required |\n",
    "| **Vision** | Built into Gemini Pro Vision | GPT-4o, GPT-4-vision |\n",
    "| **Audio** | Separate TTS API | Built-in TTS |\n",
    "| **Pricing** | Generally lower | Moderate |\n",
    "| **Setup** | Single API key | Single API key |\n",
    "\n",
    "Both are excellent! Choose based on:\n",
    "- Your existing infrastructure\n",
    "- Specific feature needs\n",
    "- Pricing considerations\n",
    "- Geographic availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "You've built a complete agentic AI system with:\n",
    "- Conversational intelligence\n",
    "- Tool/function calling\n",
    "- Multi-modal capabilities\n",
    "- Professional UI\n",
    "\n",
    "This is a foundation you can build on for real business applications!\n",
    "\n",
    "### Next Steps:\n",
    "1. Try the Week 2 Exercise to build your own custom assistant\n",
    "2. Explore Week 3 for more advanced AI techniques\n",
    "3. Build something for your own business or project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
